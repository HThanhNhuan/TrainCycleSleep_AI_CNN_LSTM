import glob
import os
import numpy as np
import scipy.signal
import tensorflow as tf
from datetime import datetime, timedelta
from sklearn.metrics import classification_report, cohen_kappa_score, f1_score, confusion_matrix
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from sklearn.utils.multiclass import unique_labels

from TrainCNN6lop import (
    hmm_smoothing_viterbi, CONFIG, load_single_subject, SEED, load_trained_model_for_inference
)
from fine_tune_subject_v2_CNN import (
    run_finetuning_for_subject as run_finetuning_for_subject_cnn
)
SLEEP_IMPACT_FACTORS_DETAIL = {
    "thanh_thieu_nien_tre": {
        "min_age": 15, "max_age": 30,
        "factors": [
            {"desc": "√Åp l·ª±c t√¢m l√Ω: Stress h·ªçc t·∫≠p, c√¥ng vi·ªác, lo √¢u, r·ªëi lo·∫°n c·∫£m x√∫c.", "impacts": ["Wake", "REM", "N3"]},
            {"desc": "Th√≥i quen sinh ho·∫°t: S·ª≠ d·ª•ng thi·∫øt b·ªã ƒëi·ªán t·ª≠, √°nh s√°ng xanh.", "impacts": ["Wake", "N1", "N2"]},
            {"desc": "Gi·ªù gi·∫•c ng·ªß kh√¥ng ƒë·ªÅu, th·ª©c khuya.", "impacts": ["N3", "REM", "Wake"]},
            {"desc": "Ti√™u th·ª• ch·∫•t k√≠ch th√≠ch (caffeine, r∆∞·ª£u, thu·ªëc l√°).", "impacts": ["Wake", "REM"]},
        ]
    },
    "trung_nien": {
        "min_age": 31, "max_age": 65,
        "factors": [
            {"desc": "√Åp l·ª±c cu·ªôc s·ªëng: CƒÉng th·∫≥ng c√¥ng vi·ªác, t√†i ch√≠nh, gia ƒë√¨nh.", "impacts": ["Wake", "N3"]},
            {"desc": "C√°c b·ªánh l√Ω n·ªÅn: Ng∆∞ng th·ªü khi ng·ªß, ƒêau m·∫°n t√≠nh, B√©o ph√¨.", "impacts": ["N3", "Wake"]},
            {"desc": "Thay ƒë·ªïi hormone (n·ªØ gi·ªõi: ti·ªÅn m√£n kinh, m√£n kinh g√¢y b·ªëc h·ªèa).", "impacts": ["Wake"]},
            {"desc": "C√°c b·ªánh l√Ω kh√°c: Cao huy·∫øt √°p, ti·ªÉu ƒë∆∞·ªùng.", "impacts": ["N3", "Wake"]},
        ]
    },
    "cao_tuoi": {
        "min_age": 66, "max_age": 120,
        "factors": [
            {"desc": "Thay ƒë·ªïi sinh l√Ω t·ª± nhi√™n: Gi·∫£m ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß s√¢u, gi·∫£m melatonin.", "impacts": ["N3", "N2"]},
            {"desc": "R·ªëi lo·∫°n nh·ªãp sinh h·ªçc (th·ª©c d·∫≠y s·ªõm).", "impacts": ["TotalSleepTime"]},
            {"desc": "C√°c b·ªánh l√Ω v√† thu·ªëc: Ti·ªÉu ƒë√™m, Ng∆∞ng th·ªü khi ng·ªß, H·ªôi ch·ª©ng ch√¢n kh√¥ng y√™n.", "impacts": ["Wake"]},
            {"desc": "ƒêau x∆∞∆°ng kh·ªõp, b·ªánh tim m·∫°ch, Alzheimer.", "impacts": ["N3", "Wake"]},
            {"desc": "C√°c y·∫øu t·ªë t√¢m l√Ω - x√£ h·ªôi: C√¥ ƒë∆°n, tr·∫ßm c·∫£m, s·ª± thay ƒë·ªïi l·ªõn (ngh·ªâ h∆∞u).", "impacts": ["Wake", "REM"]},
        ]
    }
}

SLEEP_STAGE_IMPACT_SUMMARY = {
    "Wake": {
        "desc": "Giai ƒëo·∫°n t·ªânh t√°o gi·ªØa c√°c chu k·ª≥ ng·ªß.",
        "function": "Gi√∫p n√£o chuy·ªÉn giai ƒëo·∫°n, th∆∞·ªùng ng·∫Øn (d∆∞·ªõi 8%).",
        "if_high": "T·ªâ l·ªá Wake cao l√†m gi·∫£m ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß, g√¢y m·ªát m·ªèi, u·ªÉ o·∫£i.", "if_low": "",
        "improve": "Tr√°nh caffeine/r∆∞·ª£u, gi·∫£m stress, gi·ªØ ph√≤ng ng·ªß t·ªëi v√† y√™n tƒ©nh."
    },
    "N1": {
        "desc": "Giai ƒëo·∫°n ng·ªß n√¥ng, d·ªÖ b·ªã ƒë√°nh th·ª©c.",
        "function": "Chuy·ªÉn ti·∫øp t·ª´ t·ªânh sang ng·ªß s√¢u h∆°n.",
        "if_high": "N·∫øu qu√° nhi·ªÅu N1 ‚Üí gi·∫•c ng·ªß b·ªã ph√¢n m·∫£nh, kh√¥ng ph·ª•c h·ªìi.", "if_low": "",
        "improve": "Gi·ªØ m√¥i tr∆∞·ªùng y√™n tƒ©nh, nhi·ªát ƒë·ªô m√°t, tr√°nh th·ª©c khuya."
    },
    "N2": {
        "desc": "Giai ƒëo·∫°n ng·ªß v·ª´a ‚Äì chi·∫øm ph·∫ßn l·ªõn th·ªùi gian ng·ªß.",
        "function": "C·ªßng c·ªë tr√≠ nh·ªõ v√† h·ªìi ph·ª•c c∆° b·∫Øp nh·∫π.",
        "if_high": "N·∫øu qu√° nhi·ªÅu m√† N3/REM th·∫•p ‚Üí ng·ªß ch∆∞a ƒë·ªß s√¢u ho·∫∑c do stress.",
        "if_low": "T·ªâ l·ªá N2 th·∫•p b·∫•t th∆∞·ªùng c√≥ th·ªÉ do gi·∫•c ng·ªß b·ªã gi√°n ƒëo·∫°n nhi·ªÅu.",
        "improve": "TƒÉng v·∫≠n ƒë·ªông ban ng√†y, ki·ªÉm so√°t lo √¢u, duy tr√¨ l·ªãch ng·ªß ƒë·ªÅu ƒë·∫∑n."
    },
    "N3": {
        "desc": "Gi·∫•c ng·ªß s√¢u, quan tr·ªçng cho ph·ª•c h·ªìi th·ªÉ ch·∫•t.",
        "function": "TƒÉng ti·∫øt hormone tƒÉng tr∆∞·ªüng, t√°i t·∫°o m√¥, tƒÉng mi·ªÖn d·ªãch.",
        "if_low": "Thi·∫øu N3 ‚Üí d·ªÖ m·ªát, ƒëau nh·ª©c, kh√≥ t·∫≠p trung, suy gi·∫£m mi·ªÖn d·ªãch.", "if_high": "",
        "improve": "T·∫≠p th·ªÉ d·ª•c ƒë·ªÅu ƒë·∫∑n, gi·ªØ ph√≤ng t·ªëi, tr√°nh caffeine & r∆∞·ª£u bia."
    },
    "REM": {
        "desc": "Giai ƒëo·∫°n m∆°, ph·ª•c h·ªìi n√£o b·ªô v√† c·∫£m x√∫c.",
        "function": "C·ªßng c·ªë tr√≠ nh·ªõ, c√¢n b·∫±ng c·∫£m x√∫c, tƒÉng c∆∞·ªùng s√°ng t·∫°o.",
        "if_low": "Thi·∫øu REM ‚Üí kh√≥ t·∫≠p trung, hay qu√™n, d·ªÖ c√°u g·∫Øt, gi·∫£m kh·∫£ nƒÉng s√°ng t·∫°o.", "if_high": "",
        "improve": "Gi·∫£m stress, thi·ªÅn ƒë·ªãnh, ng·ªß ƒë·ªß 7‚Äì9h, tr√°nh th·ª©c khuya."
    }
}
def get_optimal_wakeup_times(sleep_stage_seq, start_time, choice, age, gender):
    optimal_times = []
    if choice == '1':
        for i, stage in enumerate(sleep_stage_seq): # type: ignore
            wakeup_time = start_time + timedelta(seconds=(i + 1) * 30)
            if stage in ['N1', 'N2', 'REM']:
                optimal_times.append(wakeup_time.strftime("%H:%M"))
    elif choice == '2':
        total_minutes = len(sleep_stage_seq) * 0.5 # m·ªói sample = 0.5 ph√∫t
        num_cycles = int(total_minutes // 90) # type: ignore
        for i in range(1, num_cycles + 1):
            wakeup_time = start_time + timedelta(minutes=90 * i)
            optimal_times.append(wakeup_time.strftime("%H:%M"))
    else:
        print("‚ö†Ô∏è L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: 90 ph√∫t.")
        return get_optimal_wakeup_times(sleep_stage_seq, start_time, '2', age, gender)

    if choice == '1':
        if gender.lower() == 'nam':
            print("üí° Nam gi·ªõi th∆∞·ªùng c√≥ √≠t gi·∫•c ng·ªß REM h∆°n, c·∫ßn ƒë·∫£m b·∫£o ng·ªß s√¢u.")
        elif gender.lower() == 'n·ªØ':
            print("üí° N·ªØ gi·ªõi th∆∞·ªùng c√≥ nhi·ªÅu REM h∆°n, quan tr·ªçng cho tr√≠ nh·ªõ & c·∫£m x√∫c.")
    elif choice == '2' and age.isdigit() and int(age) > 65:
        print("üí° Ng∆∞·ªùi l·ªõn tu·ªïi th∆∞·ªùng ng·ªß ng·∫Øn h∆°n, c√≥ th·ªÉ th·ª≠ d·∫≠y s·ªõm h∆°n.")

    unique_times = []
    if optimal_times:
        unique_times.append(optimal_times[0])
        for t in optimal_times[1:]:
            if t != unique_times[-1]:
                unique_times.append(t)

    return unique_times
def calculate_sleep_quality_score(stage_counts, age):
    """
    T√≠nh to√°n ƒëi·ªÉm ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß d·ª±a tr√™n t·ªâ l·ªá c√°c giai ƒëo·∫°n.
    """
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return 0, "Kh√¥ng ƒë·ªß d·ªØ li·ªáu"

    age_int = int(age) if age.isdigit() else 40

    THRESHOLDS = {
        'N3': {'range': (0.13, 0.23) if age_int > 60 else (0.15, 0.25), 'weight': 40},
        'REM': {'range': (0.18, 0.23) if age_int > 60 else (0.20, 0.25), 'weight': 35},
        'Wake': {'range': (0.02, 0.08), 'weight': 25}
    }

    total_score = 0

    for stage in ['N3', 'REM']:
        percentage = stage_counts.get(stage, 0) / total_epochs
        min_p, max_p = THRESHOLDS[stage]['range']
        weight = THRESHOLDS[stage]['weight']
        
        if percentage >= min_p:
            stage_score = min(1.0, (percentage - min_p) / (max_p - min_p))
        else:
            stage_score = max(0, percentage / min_p)
        total_score += stage_score * weight

    wake_percentage = stage_counts.get('Wake', 0) / total_epochs
    min_p_wake, max_p_wake = THRESHOLDS['Wake']['range']
    if wake_percentage <= max_p_wake:
        wake_score = 1.0
    else:
        wake_score = max(0, 1.0 - (wake_percentage - max_p_wake) / (0.20 - max_p_wake)) # Gi·∫£m d·∫ßn ƒë·∫øn 20%
    total_score += wake_score * THRESHOLDS['Wake']['weight']

    final_score = int(np.clip(total_score, 0, 100))
    rating = "T·ªët" if final_score >= 75 else "Trung b√¨nh" if final_score >= 50 else "C·∫ßn c·∫£i thi·ªán"
    return final_score, rating

def generate_stage_impact_report(stage_counts, age, stage_summary):
    """
    T·∫°o b·∫£ng ph√¢n t√≠ch ƒë·ªông, c√° nh√¢n h√≥a v·ªÅ ·∫£nh h∆∞·ªüng c·ªßa t·ª´ng giai ƒëo·∫°n gi·∫•c ng·ªß.
    """
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return ["\n‚ö†Ô∏è Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t·∫°o b·∫£ng ·∫£nh h∆∞·ªüng."]

    lines = ["\n**üìã B·∫¢NG PH√ÇN T√çCH ·∫¢NH H∆Ø·ªûNG C√ÅC GIAI ƒêO·∫†N GI·∫§C NG·ª¶ (C√Å NH√ÇN H√ìA)**",
             "| Giai ƒëo·∫°n | Vai tr√≤ | Tr·∫°ng th√°i | ·∫¢nh h∆∞·ªüng ti·ªÅm t√†ng | G·ª£i √Ω c·∫£i thi·ªán |",
             "| :--- | :--- | :--- | :--- | :--- |"]

    age_int = int(age) if age.isdigit() else 40
    thresholds = {
        'Wake': (0.02, 0.08),
        'N1': (0.02, 0.08),
        'N2': (0.45, 0.55),
        'N3': (0.13, 0.23) if age_int > 60 else (0.15, 0.25),
        'REM': (0.18, 0.23) if age_int > 60 else (0.20, 0.25),
    }

    for stage, (low, high) in thresholds.items():
        pct = stage_counts.get(stage, 0) / total_epochs
        status = "‚úÖ T·ªët"
        effect = "C√°c ch·ªâ s·ªë trong ng∆∞·ª°ng kh·ªèe m·∫°nh."

        if pct < low:
            status = f"‚¨áÔ∏è Th·∫•p ({pct:.1%})"
            effect = stage_summary[stage].get("if_low", "Kh√¥ng c√≥ ·∫£nh h∆∞·ªüng ti√™u c·ª±c ƒë√°ng k·ªÉ.")
        elif pct > high:
            status = f"‚¨ÜÔ∏è Cao ({pct:.1%})"
            effect = stage_summary[stage].get("if_high", "C√≥ th·ªÉ l√† d·∫•u hi·ªáu c·ªßa gi·∫•c ng·ªß k√©m s√¢u.")

        lines.append(
            f"| **{stage}** | {stage_summary[stage]['function']} | {status} | {effect} | {stage_summary[stage]['improve']} |"
        )

    return lines

def get_personalized_advice(age, gender, stage_counts, sleep_impact_factors_detail, user_factors=None):
    advice = []
    
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return ["‚ö†Ô∏è Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch v√† ƒë∆∞a ra l·ªùi khuy√™n."]
        
    # ƒê·ªãnh nghƒ©a ng∆∞·ª°ng v√† m√¥ t·∫£
    THRESHOLDS = {
        'N3': {'min_percent': 0.15, 'desc': "Gi·∫•c ng·ªß s√¢u (N3)", 'emoji': 'üí§'}, # C·∫ßn > 15%
        'REM': {'min_percent': 0.20, 'desc': "Gi·∫•c ng·ªß REM", 'emoji': 'üß†'}, # C·∫ßn > 20%
        'Wake': {'max_percent': 0.10, 'desc': "T·ªâ l·ªá th·ª©c gi·∫•c (Wake)", 'emoji': '‚ö°Ô∏è'} # C·∫ßn < 10%
    }
    
    poor_stages = []
    
    for stage, config in THRESHOLDS.items():
        count = stage_counts.get(stage, 0)
        percentage = count / total_epochs
        
        if 'min_percent' in config and percentage < config['min_percent']:
            poor_stages.append({'stage': stage, 'percent': percentage, 'config': config})
        elif 'max_percent' in config and percentage > config['max_percent']:
            poor_stages.append({'stage': stage, 'percent': percentage, 'config': config})

    if user_factors:
        advice.append("\n--- üß© C√ÅC Y·∫æU T·ªê NGO·∫†I C·∫¢NH GHI NH·∫¨N ---")
        if user_factors.get("stress"):
            advice.append("‚ö†Ô∏è B·∫°n ƒëang c√≥ d·∫•u hi·ªáu cƒÉng th·∫≥ng. Stress l√†m tƒÉng th·ªùi gian Wake v√† gi·∫£m REM.")
        if user_factors.get("late_night"):
            advice.append("üåô Th·ª©c khuya l√†m r·ªëi lo·∫°n nh·ªãp sinh h·ªçc, gi·∫£m gi·∫•c ng·ªß s√¢u (N3).")
        if user_factors.get("device_usage"):
            advice.append("üì± S·ª≠ d·ª•ng thi·∫øt b·ªã ƒëi·ªán t·ª≠ tr∆∞·ªõc khi ng·ªß c√≥ th·ªÉ l√†m gi·∫£m ch·∫•t l∆∞·ª£ng N2 v√† REM.")
        if user_factors.get("caffeine"):
            advice.append("‚òï Caffeine c√≥ th·ªÉ k√©o d√†i th·ªùi gian Wake v√† gi·∫£m REM n·∫øu d√πng sau 16h.")
        if user_factors.get("alcohol"):
            advice.append("üç∑ R∆∞·ª£u, thu·ªëc l√° l√†m gi·∫£m N3 v√† REM, khi·∫øn gi·∫•c ng·ªß kh√¥ng ph·ª•c h·ªìi.")
        if not user_factors.get("exercise"):
            advice.append("üèÉ‚Äç‚ôÇÔ∏è Thi·∫øu v·∫≠n ƒë·ªông l√†m gi·∫£m th·ªùi l∆∞·ª£ng N3. H√£y t·∫≠p th·ªÉ d·ª•c nh·∫π bu·ªïi s√°ng ho·∫∑c chi·ªÅu.")

    age_int = int(age)
    age_group_key = None
    if 15 <= age_int <= 30:
        age_group_key = "thanh_thieu_nien_tre"
    elif 31 <= age_int <= 65:
        age_group_key = "trung_nien"
    elif age_int >= 66:
        age_group_key = "cao_tuoi"

    if not age_group_key:
        advice.append(f"Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c nh√≥m tu·ªïi cho {age_int}.")
        return advice

    all_potential_factors = sleep_impact_factors_detail[age_group_key]['factors']
    
    if poor_stages:
        advice.append(f"D·ª±a tr√™n nh√≥m tu·ªïi ({age_int}), ch√∫ng t√¥i ƒë√£ **k·∫øt h·ª£p** k·∫øt qu·∫£ ph√¢n t√≠ch gi·∫•c ng·ªß v·ªõi c√°c y·∫øu t·ªë b√™n ngo√†i c√≥ kh·∫£ nƒÉng g√¢y ra v·∫•n ƒë·ªÅ c·ªßa b·∫°n:")
        
        for p_stage in poor_stages:
            stage_name = p_stage['stage']
            stage_desc = p_stage['config']['desc']
            stage_percent = p_stage['percent'] * 100
            stage_emoji = p_stage['config']['emoji']

            advice.append(f"\n--- {stage_emoji} V·∫•n ƒë·ªÅ Ch√≠nh: {stage_desc} ({stage_percent:.1f}%) ---")

            current_factors = [
                f['desc'] for f in all_potential_factors 
                if stage_name in f['impacts']
            ]
            
            if current_factors:
                advice.append(f"üí° CƒÉn c·ª© theo nh√≥m tu·ªïi, **{stage_desc} th·∫•p/cao** c√≥ th·ªÉ li√™n quan ƒë·∫øn c√°c y·∫øu t·ªë ti·ªÅm ·∫©n sau:")
                advice.extend([f"   - {f}" for f in current_factors])

            if stage_name == 'Wake' and user_factors and user_factors.get('device_usage'):
                advice.append("üì± **K·∫øt n·ªëi tr·ª±c ti·∫øp**: T·ªâ l·ªá Wake cao v√† b·∫°n c√≥ d√πng ƒëi·ªán tho·∫°i tr∆∞·ªõc ng·ªß ‚Üí kh·∫£ nƒÉng cao √°nh s√°ng xanh ƒëang ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn gi·∫•c ng·ªß c·ªßa b·∫°n.")
            if stage_name == 'N3' and user_factors and user_factors.get('late_night'):
                advice.append("üåô **K·∫øt n·ªëi tr·ª±c ti·∫øp**: T·ªâ l·ªá N3 th·∫•p v√† b·∫°n c√≥ th√≥i quen th·ª©c khuya ‚Üí n√™n c·ªë ƒë·ªãnh gi·ªù ng·ªß s·ªõm h∆°n ƒë·ªÉ c·∫£i thi·ªán gi·∫•c ng·ªß s√¢u.")

        advice.append("\n--- ‚úÖ L·ªúI KHUY√äN H√ÄNH ƒê·ªòNG T·ªîNG QU√ÅT ---")
        
        if any(p['stage'] == 'N3' for p in poor_stages):
            advice.append("üí§ ƒê·ªÉ tƒÉng c∆∞·ªùng **Gi·∫•c ng·ªß s√¢u (N3)**: T·∫≠p trung v√†o th√≥i quen ng·ªß ƒë·ªÅu ƒë·∫∑n, ƒë·∫£m b·∫£o ph√≤ng ng·ªß t·ªëi, m√°t, y√™n tƒ©nh, v√† tƒÉng c∆∞·ªùng t·∫≠p th·ªÉ d·ª•c v√†o ban ng√†y.")
        
        if any(p['stage'] == 'REM' for p in poor_stages):
            advice.append("üß† ƒê·ªÉ c·∫£i thi·ªán **t·ªâ l·ªá REM**: H·∫°n ch·∫ø tuy·ªát ƒë·ªëi c√°c ch·∫•t k√≠ch th√≠ch (r∆∞·ª£u, caffeine) 4-6 gi·ªù tr∆∞·ªõc khi ng·ªß v√† th·ª±c hi·ªán c√°c b√†i t·∫≠p th∆∞ gi√£n (thi·ªÅn, th·ªü s√¢u) ƒë·ªÉ gi·∫£m stress.")
            
        if any(p['stage'] == 'Wake' for p in poor_stages):
            advice.append("‚ö°Ô∏è ƒê·ªÉ gi·∫£m **T·ªâ l·ªá th·ª©c gi·∫•c (Wake)**: ƒê√°nh gi√° l·∫°i vi·ªác s·ª≠ d·ª•ng thi·∫øt b·ªã ƒëi·ªán t·ª≠, √°nh s√°ng xanh 1 gi·ªù tr∆∞·ªõc ng·ªß. N·∫øu Wake cao v√† b·∫°n c√≥ d·∫•u hi·ªáu ng√°y, c·∫ßn c√¢n nh·∫Øc kh√°m b√°c sƒ© chuy√™n khoa h√¥ h·∫•p.")
            
        if gender.lower() == 'nam':
            advice.append("üí° **D√†nh cho Nam gi·ªõi**: C·∫ßn ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng N3 ƒë·ªÉ ph·ª•c h·ªìi th·ªÉ ch·∫•t t·ªët nh·∫•t.")
        elif gender.lower() == 'n·ªØ':
            advice.append("üí° **D√†nh cho N·ªØ gi·ªõi**: D·ªÖ b·ªã ·∫£nh h∆∞·ªüng b·ªüi stress v√† thay ƒë·ªïi hormone, c·∫ßn ∆∞u ti√™n c√°c k·ªπ thu·∫≠t gi·∫£m lo √¢u.")
    else:
        advice.append("üéâ D·ªØ li·ªáu ph√¢n t√≠ch cho th·∫•y c√°c ch·ªâ s·ªë N3, REM v√† Wake c·ªßa b·∫°n ƒëang ·ªü m·ª©c l√Ω t∆∞·ªüng. H√£y ti·∫øp t·ª•c duy tr√¨ th√≥i quen sinh ho·∫°t hi·ªán t·∫°i!")
    
    return advice
def generate_sleep_quality_table(stage_counts, sleep_start_time, age):
    """
    (C·∫¢I TI·∫æN) T·∫°o b·∫£ng t√≥m t·∫Øt ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫πp h∆°n
    v√† ƒë√°nh gi√° chi ti·∫øt h∆°n.
    """
    total_epochs = sum(stage_counts.values())
    if total_epochs == 0:
        return ["\n‚ö†Ô∏è Kh√¥ng c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t·∫°o b·∫£ng ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß."]

    age_int = int(age) if age.isdigit() else 40 # M·∫∑c ƒë·ªãnh tu·ªïi trung ni√™n
    
    THRESHOLDS = {
        'Wake': {'range': (0.02, 0.08), 'desc': "Th·ª©c gi·∫•c", 'role': "Th·ªùi gian th·ª©c trong ƒë√™m."},
        'N1':   {'range': (0.02, 0.08), 'desc': "Ng·ªß n√¥ng", 'role': "Giai ƒëo·∫°n chuy·ªÉn ti·∫øp, d·ªÖ b·ªã ƒë√°nh th·ª©c."},
        'N2':   {'range': (0.45, 0.55), 'desc': "Ng·ªß v·ª´a", 'role': "Chi·∫øm ph·∫ßn l·ªõn th·ªùi gian ng·ªß, c·ªßng c·ªë tr√≠ nh·ªõ."},
        'N3':   {'range': (0.13, 0.23) if age_int > 60 else (0.15, 0.25), 'desc': "Ng·ªß s√¢u", 'role': "Ph·ª•c h·ªìi th·ªÉ ch·∫•t, tƒÉng tr∆∞·ªüng, th·∫£i ƒë·ªôc n√£o."},
        'REM':  {'range': (0.18, 0.23) if age_int > 60 else (0.20, 0.25), 'desc': "Ng·ªß m∆°", 'role': "X·ª≠ l√Ω c·∫£m x√∫c, s√°ng t·∫°o, c·ªßng c·ªë k·ªπ nƒÉng."}
    }

    table_data = []
    STAGE_ORDER = ['Wake', 'N1', 'N2', 'N3', 'REM']

    for stage in STAGE_ORDER:
        count = stage_counts.get(stage, 0)
        percentage = count / total_epochs

        total_minutes = count * 0.5
        hours = int(total_minutes // 60)
        minutes = int(total_minutes % 60)
        duration_str = f"{hours}h {minutes}m"

        threshold_info = THRESHOLDS.get(stage)
        assessment_str = "N/A"
        recommendation_str = "N/A"

        if threshold_info:
            min_p, max_p = threshold_info['range']
            recommendation_str = f"{min_p*100:.0f}% - {max_p*100:.0f}%"
            
            if percentage < min_p * 0.8: # R·∫•t th·∫•p
                assessment_str = "R·∫•t th·∫•p ‚ö†Ô∏è"
            elif percentage < min_p:
                assessment_str = "Th·∫•p (C·∫ßn c·∫£i thi·ªán)"
            elif percentage > max_p * 1.2: # R·∫•t cao
                assessment_str = "R·∫•t cao ‚ö†Ô∏è"
            elif percentage > max_p:
                assessment_str = "Cao (B·∫•t th∆∞·ªùng)"
            else:
                assessment_str = "T·ªët ‚úÖ"

        table_data.append({
            "Giai ƒëo·∫°n": f"{threshold_info['desc']} ({stage})",
            "M√¥ t·∫£": threshold_info['role'],
            "Th·ªùi l∆∞·ª£ng": duration_str,
            "T·ªâ l·ªá %": f"{percentage*100:.1f}%",
            "Ng∆∞·ª°ng Khuy·∫øn ngh·ªã": recommendation_str,
            "ƒê√°nh gi√°": assessment_str
        })

    df = pd.DataFrame(table_data)
    report_lines = ["\n**üìä B·∫¢NG T√ìM T·∫ÆT CH·∫§T L∆Ø·ª¢NG GI·∫§C NG·ª¶**\n"]
    report_lines.append(df.to_markdown(index=False))

    total_sleep_minutes = total_epochs * 0.5
    total_hours = int(total_sleep_minutes // 60)
    total_minutes_rem = int(total_sleep_minutes % 60)
    end_time = sleep_start_time + timedelta(minutes=total_sleep_minutes)

    summary_line = (
        f"\n*T·ªïng th·ªùi gian ghi nh·∫≠n: **{total_hours} gi·ªù {total_minutes_rem} ph√∫t** "
        f"(t·ª´ {sleep_start_time.strftime('%H:%M')} ƒë·∫øn {end_time.strftime('%H:%M')}).*"
    )
    report_lines.append(summary_line)

    return report_lines

def generate_noise_impact_report(y_true, y_pred, config, subject_id="Unknown", output_dir="final_reports"):
    os.makedirs(output_dir, exist_ok=True)

    print("\n===== üìä PH√ÇN T√çCH ·∫¢NH H∆Ø·ªûNG NHI·ªÑU =====")
    is_clean_mask = (y_true != 5) # Nh√£n nhi·ªÖu l√† 5 trong file TrainLSTM6lop.py # type: ignore

    total_samples = len(y_true)
    noise_samples = np.sum(~is_clean_mask)
    print(f"T·ªïng m·∫´u: {total_samples}, Nhi·ªÖu: {noise_samples} ({noise_samples/total_samples*100:.2f}%)")

    y_true_clean = y_true[is_clean_mask]
    y_pred_clean = y_pred[is_clean_mask]
    f1_clean = f1_score(y_true_clean, y_pred_clean, average='macro', zero_division=0) # type: ignore
    kappa_clean = cohen_kappa_score(y_true_clean, y_pred_clean)

    f1_full = f1_score(y_true, y_pred, average='macro', zero_division=0) # type: ignore
    kappa_full = cohen_kappa_score(y_true, y_pred)

    print("\n--- So s√°nh hi·ªáu su·∫•t ---")
    print(f"‚úÖ Macro F1 (S·∫°ch): {f1_clean:.4f} | Kappa (S·∫°ch): {kappa_clean:.4f}")
    print(f"üî¥ Macro F1 (ƒê·∫ßy ƒë·ªß): {f1_full:.4f} | Kappa (ƒê·∫ßy ƒë·ªß): {kappa_full:.4f}")
    print(f"üìâ M·ª©c ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa nhi·ªÖu (F1 gi·∫£m): {f1_clean - f1_full:.4f}")

    if noise_samples > 0:
        y_pred_on_noise = y_pred[~is_clean_mask]
        noise_pred_counts = pd.Series(y_pred_on_noise).value_counts().sort_index()
        print("\nüìå Ph√¢n b·ªë d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh tr√™n c√°c m·∫´u th·ª±c s·ª± l√† nhi·ªÖu:")
        for stage, count in noise_pred_counts.items(): # type: ignore
            if stage < len(config.SLEEP_STAGE_LABELS):
                print(f"  - D·ª± ƒëo√°n l√† '{config.SLEEP_STAGE_LABELS[stage]}': {count} m·∫´u ({count / noise_samples * 100:.2f}%)")

    plt.figure(figsize=(6, 6))
    plt.pie([total_samples - noise_samples, noise_samples],
            labels=["S·∫°ch", "Nhi·ªÖu"],
            autopct="%1.1f%%", colors=["#66b3ff", "#ff6666"], startangle=90)
    plt.title(f"T·ªâ l·ªá S·∫°ch vs Nhi·ªÖu ({subject_id})")
    plt.savefig(os.path.join(output_dir, f"noise_ratio_{subject_id}.png"), dpi=300)
    plt.close()

    pred_labels = [config.SLEEP_STAGE_LABELS[i] for i in y_pred]
    plt.figure(figsize=(8, 6))
    sns.countplot(x=pred_labels, order=config.SLEEP_STAGE_LABELS, palette="viridis")
    plt.title(f"Ph√¢n b·ªë d·ª± ƒëo√°n ({subject_id})")
    plt.xlabel("Giai ƒëo·∫°n")
    plt.ylabel("S·ªë m·∫´u")
    plt.savefig(os.path.join(output_dir, f"pred_distribution_{subject_id}.png"), dpi=300)
    plt.close()

def plot_sleep_timeline(y_pred, sleep_start_time, config, subject_id="Unknown", output_dir="final_reports"):
    os.makedirs(output_dir, exist_ok=True)

    epochs = np.arange(len(y_pred))
    times = [sleep_start_time + timedelta(seconds=30 * int(i)) for i in epochs]

    plt.figure(figsize=(14, 5))
    plt.step(times, y_pred, where='post', color='royalblue', linewidth=2)
    plt.yticks(range(len(config.SLEEP_STAGE_LABELS)), config.SLEEP_STAGE_LABELS)
    plt.gca().invert_yaxis() # ƒê∆∞a Wake l√™n tr√™n c√πng
    plt.xlabel("Th·ªùi gian")
    plt.ylabel("Giai ƒëo·∫°n")
    plt.title(f"Timeline gi·∫•c ng·ªß ({subject_id})")
    plt.grid(True, axis="y", linestyle="--", alpha=0.7)
    plt.tight_layout()
    plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%H:%M'))
    timeline_path = os.path.join(output_dir, f"sleep_timeline_{subject_id}.png")
    plt.savefig(timeline_path, dpi=300)
    plt.close()

    print(f"‚úÖ Timeline gi·∫•c ng·ªß ƒë√£ l∆∞u: {timeline_path}")

def run_inference_grid_search(model, X_proc, y_true):
    """
    Ch·∫°y grid search tr√™n c√°c tham s·ªë inference ƒë·ªÉ t√¨m F1-score macro t·ªët nh·∫•t.
    T∆∞∆°ng t·ª± logic trong debug_infer.py.
    """
    best = {"f1": -1}
    temps = [0.8, 1.0, 1.2, 1.5, 1.8] # <-- D√£y Temp M·ªöI
    trans_diags = [0.8, 0.5, 0.3, 0.1] # <-- D√£y Diag M·ªöI
    channel_options = [False, True] # False: normal, True: swap
    hmm_options = [True, False] # True: HMM, False: argmax

    print("\n===== üîç B·∫Øt ƒë·∫ßu Grid Search c·∫•u h√¨nh Inference =====")

    for swap in channel_options:
        X_try = X_proc[..., ::-1] if swap else X_proc
        try:
            probs = model.predict(X_try, verbose=0)
        except Exception as e:
            print(f"L·ªói khi d·ª± ƒëo√°n v·ªõi swap={swap}: {e}")
            continue

        for temp in temps:
            p_tmp = np.clip(probs, 1e-12, 1.0)**(1.0/float(temp))
            p_tmp = p_tmp / p_tmp.sum(axis=1, keepdims=True)

            for apply_hmm in hmm_options:
                if not apply_hmm:
                    preds = np.argmax(p_tmp, axis=1)
                    td = None # Kh√¥ng c√≥ HMM diag
                    f1 = f1_score(y_true, preds, average='macro', zero_division=0)
                    if f1 > best["f1"]:
                        best.update({"f1": f1, "swap": swap, "temp": temp,
                                     "apply_hmm": apply_hmm, "trans_diag": td, "preds": preds})
                    continue

                for td in trans_diags:
                    clean_eval = not np.any(y_true == 5)
                    preds = hmm_smoothing_viterbi(p_tmp, trans_diag=td, clean_eval=clean_eval)
                    f1 = f1_score(y_true, preds, average='macro', zero_division=0)
                    if f1 > best["f1"]:
                        best.update({"f1": f1, "swap": swap, "temp": temp,
                                     "apply_hmm": apply_hmm, "trans_diag": td, "preds": preds})

    print("\n--- K·∫øt qu·∫£ Grid Search ---")
    if best['f1'] > -1:
        best_config_str = (
            f"F1: {best['f1']:.4f} | Swap: {best['swap']} | Temp: {best['temp']} | "
            f"HMM: {best['apply_hmm']} | Diag: {best['trans_diag']}"
        )
        print(f"‚úÖ C·∫•u h√¨nh t·ªët nh·∫•t: {best_config_str}")
        return best["preds"]
    else:
        print("‚ö†Ô∏è Grid search kh√¥ng t√¨m th·∫•y c·∫•u h√¨nh h·ª£p l·ªá.")
        return np.argmax(model.predict(X_proc, verbose=0), axis=1)

if __name__ == "__main__":
    print("\n\n===== üí° Ph√¢n t√≠ch d·ªØ li·ªáu v√† ƒë·ªÅ xu·∫•t gi·ªù th·ª©c d·∫≠y =====")
    
    subject_to_analyze = input("‚ñ∂Ô∏è Nh·∫≠p t√™n file d·ªØ li·ªáu s√≥ng (v√≠ d·ª•: 'SC4581'): ")
    age = input("‚ñ∂Ô∏è Nh·∫≠p tu·ªïi: ")
    gender = input("‚ñ∂Ô∏è Nh·∫≠p gi·ªõi t√≠nh (Nam/N·ªØ): ")

    while True:
        sleep_start_time_str = input("‚ñ∂Ô∏è Nh·∫≠p gi·ªù ƒëi ng·ªß (HH:MM, v√≠ d·ª•: 22:00): ")
        try:
            sleep_start_time = datetime.strptime(sleep_start_time_str, "%H:%M")
            break
        except ValueError:
            print("‚ùå Sai ƒë·ªãnh d·∫°ng, th·ª≠ l·∫°i.")

    print("\nüåô M·ªôt v√†i c√¢u h·ªèi nhanh ƒë·ªÉ c√° nh√¢n h√≥a ph√¢n t√≠ch:")
    stress = input("‚ñ∂Ô∏è B·∫°n c√≥ ƒëang cƒÉng th·∫≥ng, lo √¢u ho·∫∑c stress kh√¥ng? (y/n): ").lower()
    late_night = input("‚ñ∂Ô∏è B·∫°n c√≥ th∆∞·ªùng xuy√™n th·ª©c khuya (sau 23h) kh√¥ng? (y/n): ").lower()
    device_usage = input("‚ñ∂Ô∏è B·∫°n c√≥ d√πng ƒëi·ªán tho·∫°i/m√°y t√≠nh tr∆∞·ªõc khi ng·ªß? (y/n): ").lower()
    caffeine = input("‚ñ∂Ô∏è B·∫°n c√≥ d√πng c√† ph√™, tr√† ho·∫∑c ch·∫•t k√≠ch th√≠ch bu·ªïi chi·ªÅu/t·ªëi kh√¥ng? (y/n): ").lower()
    alcohol = input("‚ñ∂Ô∏è B·∫°n c√≥ s·ª≠ d·ª•ng r∆∞·ª£u ho·∫∑c thu·ªëc l√° kh√¥ng? (y/n): ").lower()
    exercise = input("‚ñ∂Ô∏è B·∫°n c√≥ t·∫≠p th·ªÉ d·ª•c √≠t nh·∫•t 3 l·∫ßn/tu·∫ßn kh√¥ng? (y/n): ").lower()

    user_factors = {
        "stress": stress == "y",
        "late_night": late_night == "y",
        "device_usage": device_usage == "y",
        "caffeine": caffeine == "y",
        "alcohol": alcohol == "y",
        "exercise": exercise == "y"
    }

    best_model_path = None
    base_model_path = open("best_model_path.txt").read().strip()
    base_model_dir = os.path.dirname(base_model_path)
    subject_specific_model_path = os.path.join(base_model_dir, f"fine_tuned_v2_{subject_to_analyze}.keras")

    if os.path.exists(subject_specific_model_path):
        best_model_path = subject_specific_model_path
        print(f"‚úÖ T√¨m th·∫•y model ƒë√£ fine-tune ri√™ng cho subject: {best_model_path}")
    else:
        print(f"‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y model ri√™ng cho '{subject_to_analyze}'.")
        do_finetune = input("‚ñ∂Ô∏è B·∫°n c√≥ mu·ªën fine-tune m·ªôt model m·ªõi cho subject n√†y ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t? (y/n): ").lower()
        if do_finetune == 'y':
            print(f"\n===== üöÄ B·∫Øt ƒë·∫ßu Fine-tuning cho {subject_to_analyze} t·ª´ model '{base_model_path}' =====")
            best_model_path = run_finetuning_for_subject_cnn(subject_to_analyze, base_model_path)
            print(f"===== ‚úÖ Fine-tuning ho√†n t·∫•t. Model m·ªõi: '{best_model_path}' =====\n")

    if not best_model_path:
        print(f"‚ö†Ô∏è  C·∫¢NH B√ÅO: S·ª≠ d·ª•ng model chung '{base_model_path}' v√¨ kh√¥ng c√≥ model ri√™ng ho·∫∑c ng∆∞·ªùi d√πng t·ª´ ch·ªëi fine-tune. K·∫øt qu·∫£ c√≥ th·ªÉ kh√¥ng t·ªëi ∆∞u.")
        best_model_path = base_model_path

    if not best_model_path:
        print("‚ùå Kh√¥ng th·ªÉ x√°c ƒë·ªãnh model ƒë·ªÉ s·ª≠ d·ª•ng. Vui l√≤ng ch·∫°y training ho·∫∑c fine-tuning tr∆∞·ªõc.")
        exit()

    print(f"‚úÖ S·ª≠ d·ª•ng model: {best_model_path}")
    model = load_trained_model_for_inference(best_model_path)

    X_raw, y_subject_true = load_single_subject(subject_to_analyze)
    if X_raw is None:
        print(f"‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu cho subject {subject_to_analyze}.")
        exit()

    X_list = []
    for i in range(X_raw.shape[0]):
        x = X_raw[i].astype(np.float32)
        x_r = scipy.signal.resample(x, CONFIG.TARGET_LENGTH_CNN, axis=0).astype(np.float32)
        mean = x_r.mean(axis=0, keepdims=True)
        std = x_r.std(axis=0, keepdims=True) + 1e-8
        X_list.append((x_r - mean) / std)
    X_subject = np.stack(X_list).astype(np.float32)
    y_subject_true = np.array(y_subject_true)

    y_pred_final = run_inference_grid_search(model, X_subject, y_subject_true)

    if y_pred_final is not None and len(y_pred_final) > 0:
        output_dir = os.path.join(os.path.dirname(os.path.dirname(best_model_path)), "final_reports")

        try:
            os.makedirs("debug_plots_CNN", exist_ok=True)
            X = np.array(X_subject)  # ensure ndarray
            n_epochs, n_t, n_ch = X.shape
            ch_means = X.reshape(-1, n_ch).mean(axis=0)
            ch_stds = X.reshape(-1, n_ch).std(axis=0)
            np.save("debug_plots/subject_per_channel_mean.npy", ch_means)
            np.save("debug_plots/subject_per_channel_std.npy", ch_stds)
            print("DEBUG: per-channel mean/std saved:", ch_means, ch_stds)

            from scipy.signal import welch
            sf = 100  # typical sfreq ‚Äî thay n·∫øu kh√°c (m·ªôt s·ªë file in ra sfreq=100)
            fig, axs = plt.subplots(n_ch, 1, figsize=(8, 2.5 * n_ch))
            for c in range(min(n_ch, 2)): # Gi·ªõi h·∫°n v·∫Ω 2 k√™nh ƒë·ªÉ tr√°nh l·ªói n·∫øu c√≥ nhi·ªÅu k√™nh
                f, Pxx = welch(X[0, :, c], fs=sf, nperseg=512)
                axs[c].semilogy(f, Pxx)
                axs[c].set_xlabel("Hz"); axs[c].set_ylabel("PSD")
                axs[c].set_title(f"Subject {subject_to_analyze} PSD epoch 0 ch{c}")
            plt.tight_layout()
            plt.savefig(f"debug_plots/{subject_to_analyze}_epoch0_psd.png", dpi=150)
            plt.close()
            print(f"DEBUG: saved PSD -> debug_plots/{subject_to_analyze}_epoch0_psd.png")

            train_sample_path = "debug_plots/training_epoch_sample.npy"
            if os.path.exists(train_sample_path):
                train_epoch = np.load(train_sample_path)  # expects shape (time, channels)
                fig, axs = plt.subplots(n_ch, 1, figsize=(8, 2.5 * n_ch))
                for c in range(min(n_ch, 2)):
                    f_s, P_s = welch(train_epoch[:, c], fs=sf, nperseg=512)
                    f_x, P_x = welch(X[0, :, c], fs=sf, nperseg=512)
                    axs[c].semilogy(f_s, P_s, label="train", alpha=0.8)
                    axs[c].semilogy(f_x, P_x, label="subject", alpha=0.8)
                    axs[c].legend()
                    axs[c].set_title(f"PSD ch{c} train vs subject")
                plt.tight_layout()
                plt.savefig(f"debug_plots/{subject_to_analyze}_psd_vs_train.png", dpi=150)
                plt.close()
                print("DEBUG: saved PSD comparison with training sample")

        except Exception as _e:
            print("DEBUG: failed saving channel stats/PSD:", _e)

        generate_noise_impact_report(y_subject_true, y_pred_final, CONFIG, subject_id=subject_to_analyze, output_dir=output_dir)

        plot_sleep_timeline(y_pred_final, sleep_start_time, CONFIG, subject_id=subject_to_analyze, output_dir=output_dir)

        try:
            y_pred_stages = [CONFIG.SLEEP_STAGE_LABELS[int(x)] for x in np.array(y_pred_final).astype(int)]
        except Exception:
            y_pred_stages = []

        stage_counts = Counter(y_pred_stages)
        print("\nüìä Ph√¢n b·ªë Giai ƒëo·∫°n Gi·∫•c ng·ªß (S·ªë Epoch):", stage_counts)

        sleep_score, sleep_rating = calculate_sleep_quality_score(stage_counts, age)
        print("\n" + "‚ïê"*25 + " ƒê√ÅNH GI√Å T·ªîNG QUAN " + "‚ïê"*25)
        print(f"üíØ ƒêi·ªÉm ch·∫•t l∆∞·ª£ng gi·∫•c ng·ªß c·ªßa b·∫°n: {sleep_score} / 100")
        print(f"‚≠ê X·∫øp h·∫°ng: {sleep_rating}")
        print("‚ïê"*70)

        print("\n" + "‚ïê"*20 + " B√ÅO C√ÅO PH√ÇN T√çCH GI·∫§C NG·ª¶ CHI TI·∫æT " + "‚ïê"*20)

        sleep_quality_report = generate_sleep_quality_table(stage_counts, sleep_start_time, age)
        for line in sleep_quality_report:
            print(line)

        stage_impact_report = generate_stage_impact_report(stage_counts, age, SLEEP_STAGE_IMPACT_SUMMARY)
        for line in stage_impact_report:
            print(line)

        print("\n" + "‚ïê"*25 + " ƒê·ªÄ XU·∫§T GI·ªú TH·ª®C D·∫¨Y " + "‚ïê"*25)
        print("B·∫°n mu·ªën th·ª©c d·∫≠y theo ti√™u ch√≠ n√†o?")
        print("1. D·∫≠y trong giai ƒëo·∫°n nh·∫π (N1, N2, REM)")
        print("2. D·∫≠y sau m·ªói chu k·ª≥ 90 ph√∫t")
        choice = input("‚ñ∂Ô∏è Nh·∫≠p l·ª±a ch·ªçn (1 ho·∫∑c 2): ")
 
        print(f"\nüìå Ng·ªß l√∫c: {sleep_start_time_str}")
        print(f"üë§ Tu·ªïi: {age}, Gi·ªõi t√≠nh: {gender}")
 
        optimal_times = get_optimal_wakeup_times(y_pred_stages, sleep_start_time, choice, age, gender)
        if optimal_times:
            print("\n‚è∞ Gi·ªù th·ª©c d·∫≠y t·ªëi ∆∞u (ch·ªçn ch·∫ø ƒë·ªô " + choice + "):")
            for i, t in enumerate(optimal_times, 1):
                print(f"   {i}. {t}")
        else:
            print("‚ö†Ô∏è Kh√¥ng c√≥ gi·ªù th·ª©c d·∫≠y t·ªëi ∆∞u.")

        final_advice = get_personalized_advice(age, gender, stage_counts, SLEEP_IMPACT_FACTORS_DETAIL, user_factors)
 
        print("\n" + "‚ïê"*20 + " L·ªúI KHUY√äN C√Å NH√ÇN H√ìA & NGUY√äN NH√ÇN " + "‚ïê"*20)
        for i, line in enumerate(final_advice):
            print(line)
        print("‚ïê"*70)
    else:
        print(f"‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω cho subject {subject_to_analyze}.")
